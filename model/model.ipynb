{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a518f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Dense, Dropout\n",
    "from PIL import Image,ImageOps,ImageEnhance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint , ReduceLROnPlateau\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f076da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb7b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img,angle):\n",
    "    return img.rotate(angle=angle)\n",
    "\n",
    "def flip(img):\n",
    "    return ImageOps.mirror(img)\n",
    "\n",
    "def change_brightness(img,factor = 1.2):\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    return enhancer.enhance(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3c0ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (3912, 64, 64, 3)\n",
      "Result shape: (3912, 3)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "result = []\n",
    "labels = []\n",
    "le = LabelEncoder()\n",
    "le.fit(['paper', 'rock', 'scissors'])\n",
    "\n",
    "for hand in ['paper', 'rock', 'scissors']:\n",
    "    label = hand\n",
    "    class_index = le.transform([hand])[0]\n",
    "    class_label = to_categorical(class_index, num_classes=3)\n",
    "\n",
    "    paths = []\n",
    "    for r, d, f in os.walk(os.path.join(r\"C:\\\\Users\\\\USER\\\\Desktop\\\\rock paper scissors\\\\dataset\\\\train\", hand)):\n",
    "        for file in f:\n",
    "            if file.lower().endswith(\".png\"):\n",
    "                paths.append(os.path.join(r, file))\n",
    "\n",
    "    # Move this outside the inner loop\n",
    "    for path in paths:\n",
    "        img = Image.open(path).convert('RGB').resize((64, 64))\n",
    "        img = np.array(img).astype('float32') / 255.0\n",
    "        if img.shape == (64, 64, 3):\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "encoded = le1.fit_transform(labels)\n",
    "result = to_categorical(encoded, num_classes=3)\n",
    "\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "\n",
    "print('Data shape:', data.shape)\n",
    "print('Result shape:', result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f77473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data, result = shuffle(data, result, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1aa5d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3912, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reshape(-1, 3)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f520870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1525c7d8ac0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5134f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data, result, test_size=0.2, random_state=42,stratify=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7454ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "Counter({0.0: 6258, 1.0: 3129})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "flat_y = np.ravel(ytrain)\n",
    "\n",
    "print(\"Class distribution in training set:\")\n",
    "print(collections.Counter(flat_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5018deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1061. 1034. 1034.]\n",
      "Test: [265. 259. 259.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", np.sum(ytrain, axis=0))\n",
    "print(\"Test:\", np.sum(ytest, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777da402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytrain shape: (3129, 3)\n",
      "First 5 ytrain values:\n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ytrain shape:\", ytrain.shape)\n",
    "print(\"First 5 ytrain values:\\n\", ytrain[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "963e4150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(ytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d8ce8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.9830348727615457, 1: 1.0087040618955512, 2: 1.0087040618955512}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Convert one-hot to label indices\n",
    "y_train_labels = np.argmax(ytrain, axis=1)\n",
    "\n",
    "# Compute weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights:\", class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a655595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), padding='same',input_shape=(64,64,3))) \n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(16,(3,3),activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3),activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(32, (3, 3),activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3),activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3),activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3),activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3),activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(3, activation='softmax')) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec52c2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">278,227</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m278,227\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">277,875</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m277,875\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcfc6c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3912 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../dataset/train',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f818e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 804 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    '../dataset/val',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87221d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56e32cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytrain shape: (3129, 3)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ytrain shape:\", ytrain.shape)  # Should be (num_samples, 3)\n",
    "print(ytrain[:5])  # Should look like [0 1 0], etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54f5d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.h5',  \n",
    "    monitor='val_loss',         \n",
    "    save_best_only=True,        \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f309e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9136515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d6610b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape: (3129, 64, 64, 3)\n",
      "ytrain shape: (3129, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"xtrain shape:\", xtrain.shape)\n",
    "print(\"ytrain shape:\", ytrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8411b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.4668 - loss: 1.0136\n",
      "Epoch 1: val_loss improved from inf to 1.54511, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 286ms/step - accuracy: 0.4684 - loss: 1.0120 - val_accuracy: 0.3308 - val_loss: 1.5451 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.7370 - loss: 0.7210\n",
      "Epoch 2: val_loss did not improve from 1.54511\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 272ms/step - accuracy: 0.7373 - loss: 0.7205 - val_accuracy: 0.3308 - val_loss: 2.0392 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.8029 - loss: 0.6123\n",
      "Epoch 3: val_loss improved from 1.54511 to 1.40453, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 274ms/step - accuracy: 0.8030 - loss: 0.6121 - val_accuracy: 0.3308 - val_loss: 1.4045 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.8260 - loss: 0.5835\n",
      "Epoch 4: val_loss improved from 1.40453 to 0.93695, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 273ms/step - accuracy: 0.8260 - loss: 0.5835 - val_accuracy: 0.4879 - val_loss: 0.9369 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.8345 - loss: 0.5698\n",
      "Epoch 5: val_loss did not improve from 0.93695\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 270ms/step - accuracy: 0.8345 - loss: 0.5698 - val_accuracy: 0.4955 - val_loss: 1.0612 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8409 - loss: 0.5550\n",
      "Epoch 6: val_loss improved from 0.93695 to 0.62298, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 282ms/step - accuracy: 0.8411 - loss: 0.5549 - val_accuracy: 0.7739 - val_loss: 0.6230 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8611 - loss: 0.5454\n",
      "Epoch 7: val_loss did not improve from 0.62298\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 279ms/step - accuracy: 0.8612 - loss: 0.5453 - val_accuracy: 0.7995 - val_loss: 0.6302 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.8754 - loss: 0.5228\n",
      "Epoch 8: val_loss improved from 0.62298 to 0.45759, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.8756 - loss: 0.5227 - val_accuracy: 0.8978 - val_loss: 0.4576 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.8998 - loss: 0.5001\n",
      "Epoch 9: val_loss did not improve from 0.45759\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 270ms/step - accuracy: 0.8998 - loss: 0.5001 - val_accuracy: 0.8442 - val_loss: 0.5499 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9079 - loss: 0.4846\n",
      "Epoch 10: val_loss did not improve from 0.45759\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 271ms/step - accuracy: 0.9079 - loss: 0.4847 - val_accuracy: 0.8940 - val_loss: 0.4968 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9049 - loss: 0.4786\n",
      "Epoch 11: val_loss did not improve from 0.45759\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 270ms/step - accuracy: 0.9051 - loss: 0.4784 - val_accuracy: 0.8748 - val_loss: 0.5058 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9286 - loss: 0.4493\n",
      "Epoch 12: val_loss improved from 0.45759 to 0.43591, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 274ms/step - accuracy: 0.9286 - loss: 0.4492 - val_accuracy: 0.9246 - val_loss: 0.4359 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9382 - loss: 0.4347\n",
      "Epoch 13: val_loss improved from 0.43591 to 0.40079, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 277ms/step - accuracy: 0.9382 - loss: 0.4348 - val_accuracy: 0.9502 - val_loss: 0.4008 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9442 - loss: 0.4277\n",
      "Epoch 14: val_loss improved from 0.40079 to 0.39687, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 272ms/step - accuracy: 0.9442 - loss: 0.4277 - val_accuracy: 0.9425 - val_loss: 0.3969 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9489 - loss: 0.4207\n",
      "Epoch 15: val_loss improved from 0.39687 to 0.36688, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 279ms/step - accuracy: 0.9489 - loss: 0.4207 - val_accuracy: 0.9706 - val_loss: 0.3669 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9443 - loss: 0.4166\n",
      "Epoch 16: val_loss did not improve from 0.36688\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 272ms/step - accuracy: 0.9444 - loss: 0.4166 - val_accuracy: 0.9489 - val_loss: 0.3859 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9583 - loss: 0.4108\n",
      "Epoch 17: val_loss did not improve from 0.36688\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 278ms/step - accuracy: 0.9583 - loss: 0.4108 - val_accuracy: 0.9515 - val_loss: 0.3763 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9571 - loss: 0.4069\n",
      "Epoch 18: val_loss did not improve from 0.36688\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 282ms/step - accuracy: 0.9571 - loss: 0.4069 - val_accuracy: 0.9438 - val_loss: 0.3924 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9569 - loss: 0.4021\n",
      "Epoch 19: val_loss did not improve from 0.36688\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 271ms/step - accuracy: 0.9570 - loss: 0.4021 - val_accuracy: 0.9591 - val_loss: 0.3726 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9619 - loss: 0.3980\n",
      "Epoch 20: val_loss improved from 0.36688 to 0.34668, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 281ms/step - accuracy: 0.9620 - loss: 0.3979 - val_accuracy: 0.9732 - val_loss: 0.3467 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9722 - loss: 0.3864\n",
      "Epoch 21: val_loss did not improve from 0.34668\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 276ms/step - accuracy: 0.9722 - loss: 0.3864 - val_accuracy: 0.9706 - val_loss: 0.3516 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9673 - loss: 0.3855\n",
      "Epoch 22: val_loss improved from 0.34668 to 0.34043, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.9673 - loss: 0.3855 - val_accuracy: 0.9783 - val_loss: 0.3404 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9735 - loss: 0.3875\n",
      "Epoch 23: val_loss did not improve from 0.34043\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 272ms/step - accuracy: 0.9735 - loss: 0.3875 - val_accuracy: 0.9566 - val_loss: 0.3659 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9664 - loss: 0.3906\n",
      "Epoch 24: val_loss did not improve from 0.34043\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.9665 - loss: 0.3905 - val_accuracy: 0.9489 - val_loss: 0.3789 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9674 - loss: 0.3928\n",
      "Epoch 25: val_loss did not improve from 0.34043\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 273ms/step - accuracy: 0.9675 - loss: 0.3927 - val_accuracy: 0.9719 - val_loss: 0.3501 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9813 - loss: 0.3716\n",
      "Epoch 26: val_loss did not improve from 0.34043\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 271ms/step - accuracy: 0.9813 - loss: 0.3717 - val_accuracy: 0.9808 - val_loss: 0.3424 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9773 - loss: 0.3743\n",
      "Epoch 27: val_loss improved from 0.34043 to 0.33739, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.9773 - loss: 0.3742 - val_accuracy: 0.9796 - val_loss: 0.3374 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9871 - loss: 0.3617\n",
      "Epoch 28: val_loss improved from 0.33739 to 0.33603, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 273ms/step - accuracy: 0.9870 - loss: 0.3618 - val_accuracy: 0.9783 - val_loss: 0.3360 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9735 - loss: 0.3775\n",
      "Epoch 29: val_loss did not improve from 0.33603\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 272ms/step - accuracy: 0.9736 - loss: 0.3774 - val_accuracy: 0.9668 - val_loss: 0.3533 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9870 - loss: 0.3632\n",
      "Epoch 30: val_loss improved from 0.33603 to 0.33324, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 280ms/step - accuracy: 0.9869 - loss: 0.3633 - val_accuracy: 0.9796 - val_loss: 0.3332 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9770 - loss: 0.3708\n",
      "Epoch 31: val_loss did not improve from 0.33324\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 278ms/step - accuracy: 0.9771 - loss: 0.3707 - val_accuracy: 0.9757 - val_loss: 0.3410 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9881 - loss: 0.3616\n",
      "Epoch 32: val_loss improved from 0.33324 to 0.32993, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 277ms/step - accuracy: 0.9881 - loss: 0.3616 - val_accuracy: 0.9821 - val_loss: 0.3299 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9771 - loss: 0.3666\n",
      "Epoch 33: val_loss improved from 0.32993 to 0.32914, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 277ms/step - accuracy: 0.9771 - loss: 0.3666 - val_accuracy: 0.9821 - val_loss: 0.3291 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9838 - loss: 0.3685\n",
      "Epoch 34: val_loss did not improve from 0.32914\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 271ms/step - accuracy: 0.9837 - loss: 0.3685 - val_accuracy: 0.9783 - val_loss: 0.3391 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9816 - loss: 0.3664\n",
      "Epoch 35: val_loss did not improve from 0.32914\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 277ms/step - accuracy: 0.9816 - loss: 0.3664 - val_accuracy: 0.9783 - val_loss: 0.3387 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9798 - loss: 0.3699\n",
      "Epoch 36: val_loss did not improve from 0.32914\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.9798 - loss: 0.3699 - val_accuracy: 0.9834 - val_loss: 0.3338 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9847 - loss: 0.3631\n",
      "Epoch 37: val_loss did not improve from 0.32914\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 274ms/step - accuracy: 0.9847 - loss: 0.3631 - val_accuracy: 0.9808 - val_loss: 0.3376 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9849 - loss: 0.3599\n",
      "Epoch 38: val_loss did not improve from 0.32914\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 270ms/step - accuracy: 0.9848 - loss: 0.3599 - val_accuracy: 0.9796 - val_loss: 0.3378 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9875 - loss: 0.3567\n",
      "Epoch 39: val_loss did not improve from 0.32914\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 273ms/step - accuracy: 0.9875 - loss: 0.3567 - val_accuracy: 0.9808 - val_loss: 0.3338 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9813 - loss: 0.3642\n",
      "Epoch 40: val_loss did not improve from 0.32914\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 0.9813 - loss: 0.3642 - val_accuracy: 0.9821 - val_loss: 0.3378 - learning_rate: 3.1250e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9839 - loss: 0.3618\n",
      "Epoch 41: val_loss did not improve from 0.32914\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 295ms/step - accuracy: 0.9839 - loss: 0.3617 - val_accuracy: 0.9821 - val_loss: 0.3324 - learning_rate: 3.1250e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9830 - loss: 0.3619\n",
      "Epoch 42: val_loss did not improve from 0.32914\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 273ms/step - accuracy: 0.9830 - loss: 0.3618 - val_accuracy: 0.9834 - val_loss: 0.3312 - learning_rate: 3.1250e-05\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1527f9e1ed0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(xtest, ytest),\n",
    "    epochs=100,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a10daae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9865 - loss: 0.3309\n",
      "Test Accuracy: 0.9821\n",
      "Test Loss: 0.3299\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       265\n",
      "           1       0.98      0.98      0.98       259\n",
      "           2       1.00      0.97      0.98       259\n",
      "\n",
      "    accuracy                           0.98       783\n",
      "   macro avg       0.98      0.98      0.98       783\n",
      "weighted avg       0.98      0.98      0.98       783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, acc = model.evaluate(xtest, ytest, verbose=1)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "\n",
    "# Predict class probabilities\n",
    "y_pred_probs = model.predict(xtest)\n",
    "\n",
    "# Convert one-hot to class indices\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(ytest, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67fca636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 688ms/step - accuracy: 0.9849 - loss: 0.0947 - val_accuracy: 0.9745 - val_loss: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 279ms/step - accuracy: 0.9799 - loss: 0.0700 - val_accuracy: 0.9770 - val_loss: 0.0537 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 273ms/step - accuracy: 0.9816 - loss: 0.0622 - val_accuracy: 0.9770 - val_loss: 0.0541 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 279ms/step - accuracy: 0.9832 - loss: 0.0533 - val_accuracy: 0.9745 - val_loss: 0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.9841 - loss: 0.0571 - val_accuracy: 0.9757 - val_loss: 0.0534 - learning_rate: 5.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.9872 - loss: 0.0490 - val_accuracy: 0.9821 - val_loss: 0.0484 - learning_rate: 5.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 278ms/step - accuracy: 0.9852 - loss: 0.0476 - val_accuracy: 0.9770 - val_loss: 0.0556 - learning_rate: 5.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 275ms/step - accuracy: 0.9833 - loss: 0.0486 - val_accuracy: 0.9821 - val_loss: 0.0402 - learning_rate: 5.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 278ms/step - accuracy: 0.9807 - loss: 0.0540 - val_accuracy: 0.9834 - val_loss: 0.0432 - learning_rate: 5.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 279ms/step - accuracy: 0.9861 - loss: 0.0443 - val_accuracy: 0.9770 - val_loss: 0.0594 - learning_rate: 5.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 282ms/step - accuracy: 0.9845 - loss: 0.0451 - val_accuracy: 0.9796 - val_loss: 0.0504 - learning_rate: 2.5000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 278ms/step - accuracy: 0.9866 - loss: 0.0393 - val_accuracy: 0.9847 - val_loss: 0.0433 - learning_rate: 2.5000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 282ms/step - accuracy: 0.9863 - loss: 0.0418 - val_accuracy: 0.9847 - val_loss: 0.0427 - learning_rate: 1.2500e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Optional: Load best weights\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# Step 1: Recompile with a lower learning rate\n",
    "fine_tune_lr = 1e-4  # Or 5e-5\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=fine_tune_lr),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 2: Set up callbacks (reusing if already defined)\n",
    "checkpoint = ModelCheckpoint(\"finetuned_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2)\n",
    "\n",
    "# Step 3: Fit again with fewer epochs\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(xtest, ytest),\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d173563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9844 - loss: 0.0395\n",
      "Fine-tuned Test Accuracy: 0.9821\n",
      "Fine-tuned Test Loss: 0.0402\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"finetuned_model.keras\")\n",
    "\n",
    "loss, acc = model.evaluate(xtest, ytest)\n",
    "print(f\"Fine-tuned Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Fine-tuned Test Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0a3906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"rps_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4878857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
